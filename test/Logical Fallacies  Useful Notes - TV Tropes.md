_"A foolish consistency is the hobgoblin of little minds, adored by little statesmen and philosophers and divines."_

Logic. Every story needs some of it, unless you just want a series of unconnected images and no plot to speak of.

The problem is that logic requires writers to think pretty hard about what they write, and not all writers have time or inclination to do so. So they take shortcuts, creating fallacies which at best can lead to plot holes or, at worst, undermine the entire story.

Fallacies are common errors in logic. By strict standards, fallacies don't address the truth of the premises or syllogism; they only address the _validity of the logic_, and as the Sound/Valid/True rule demonstrates, "truth" and "validity" are not the same thing when speaking of formal logic. There is a reason there are Critical Thinking classes.

Where deductive logic is valid, the conclusion must be true if the premises are true. "If it rains, then the sidewalk will be wet" is valid, so if you know that it rained, you know that the sidewalk will be wet. If you simply reverse the terms and say "if the sidewalk is wet, then it rained", this would not be valid; likewise, negating the terms, yielding "if it did not rain, then the sidewalk is not wet", is also invalid. To correct this, you need to construct a "contra-positive," where you reverse the terms as well as negating them to get "if the sidewalk is not wet, then it did not rain".

However, inductive logic<sup>note&nbsp;</sup>  involves reasonable inferences of what might be true, but not necessarily. A sidewalk could be wet due to a passing street sweeping vehicle or neighbours carelessly watering their lawns. Seeing a wet sidewalk and concluding that there was rain is fallacious — not deductively valid — but it is not necessarily false, nor is it necessarily an unreasonable inference to make.

Logical fallacies are faulty deductive reasoning. This doesn't mean that they aren't effective at persuading. Many of them are extremely effective tools of persuasion. The key is that there are two primary routes of persuasion: the central (logical) route and the peripheral (emotional) route. To persuade someone using the central route, you _need_ logic; a logical fallacy will make your argument fall flat on its face. To persuade someone using the peripheral route, you don't need logic; you simply need to play on their emotions. Some people are impassive to emotional appeals, and so you must use logic to persuade them; others are confused by logic, and so must be persuaded through emotion.

However, one must keep in mind that — depending on the surrounding circumstances — a deductively fallacious argument may still, nonetheless, be a reasonable and (inductively) logical argument that has decent prospects of being true despite the deductive logic being invalid. A classic example is if someone were to examine a million swans and note that all of them were white. It would be a (deductively) logical fallacy to conclude that "all swans are white". You could not make that conclusion unless you know that you had examined all swans in the universe. That doesn't make it illogical, however. If no one had ever seen a black swan, it might be rather sensible. Plus, this whole type of analysis is complicated when you talk about statistical trends. For these kinds of special cases, see the Fallacy Fallacy below.

For examples of characters falling into these fallacies (intentionally on the writer's part), see the main Logical Fallacies index. This is not an exhaustive list, and there are more fallacies in that index.

___

## Specific fallacies:

    open/close all folders 

    Ad Hoc 

Ad hoc is a fallacious debating tactic (also called a "just so story" or an "ad hoc rescue") in which an explanation of why a particular thing _may be_ is substituted for an argument as to why it _is_; since it is therefore not an argument, it is not technically a fallacy, but is usually listed as one because it is a substitution for a valid argument. It is similar in form to Moving the Goalposts, but protects the argument by adding additional speculative terms rather than changing the meaning of existing ones.

Users of ad hoc claims generally believe the excuses and rationalisations serve to shore up the original hypothesis, but in fact each additional speculative term weakens it. This is both due to the speculations being based simply on the faith that there _might_ be an explanation, and because each additional term makes the hypothesis weaker according to the principle of Occam's Razor.

"Possibly," "probably," "maybe," "might" and "could" are all good markers of _ad hoc_ claims.

It's a very common sight in justifying edits aimed at any supposedly negative trope, particularly if that edit calls upon things that _might_ have happened to cause the item described. For example:

_"There is a glaring Plot Hole in this movie, since it is said that magic cannot work in the Dark Zone, yet later on Alice resurrects Bob while fighting the Phantom Lord."_

_"It's possible that Alice learned a form of magic that does work in the Dark Zone, and that's what she used to save Bob."_

Here the second poster is not presenting evidence: rather, they are explaining what the evidence they _do not have_ ought to look like.

    Affirming the Consequent 

This claim is most simply put as:

If A, then B.  
B.  
Therefore, A.

It's a fallacy because at no point is it shown that A is the _only_ possible cause of B; therefore, even if B is true, A can still be false. For example:

If my car was a Ferrari, it would be able to travel at over a hundred miles per hour.  
I clocked my car at 121 miles per hour.  
Therefore, my car is a Ferrari.  

This is popular in conspiracy theories. Here the fallacy is fairly obvious; given the evidence, the car _might_ be a Ferrari, but it might also be a Bugatti, Lamborghini, or any other model of performance car, since the ability to travel that fast is not unique to Ferraris. Hell, it might even be a Subaru Outback. Note that while this may appear to call all hypothesis / evidence experiments fallacious, they are based on additional evaluations of the likelihood of _other_ theories, thus establishing that A _is_ a likely cause of B.

    Anecdotal Fallacy 

Anecdotal evidence is basically saying "_X_ happened to me/someone I know/someone I heard about" in a discussion and/or argument. If it's true that _X_ happened to this person (which is not proven by the assertion alone), it proves only that _X_ is not impossible. It most certainly does not establish that _X_ has ever happened more than once, or that _X_ is common or pervasive - and that's what this fallacy about. The anecdotal fallacy is using anecdotes instead of actual statistics and making general rules and grand claims off them, an accurate picture of the reality of the matter be damned. Crops up often in heated arguments and amidst Hasty Generalisations, whereby an anecdote is not just used to illustrate or critique a general rule but as 'proof'<sup>note&nbsp;</sup>  in itself. As they say, "The plural of 'anecdote' is not 'data'".

"According to statistics, smoking causes you to die young. But my Grandmother Sally smoked like a chimney and lived until she was 95, so clearly, the statistics are wrong."

As a rebuttal, one might simply point out that they met a man on the way home who said that anecdotal evidence doesn't prove anything.

Anecdotal Evidence is extremely prone to Confirmation Bias; when it doesn't fit one's viewpoint, it can be very easily dismissed as this fallacy. If it does fit one's viewpoint, it's a perfect example of that viewpoint applying to real people in the real world.

    Appeal to Consequences 

The Appeal to Consequences happens when the truth or falsity of a statement is decided by the positive or negative consequences of it.

If climate change is occurring _and_ is caused by humans, then we are obligated to do something to stop or slow it.  
The most effective way to do so is for businesses to cut down on carbon emissions.  
The short term costs of cutting carbon emissions would be economically devastating.  
Therefore, climate change is either not occurring, not caused by humans, or both.

Or, conversely:

If climate change is occurring _and_ is caused by humans, then we are obligated to do something to stop or slow it.  
The most effective way to do so is for businesses to cut down on carbon emissions.  
The long-term economic benefits of stopping global warming will be enormous.  
Therefore, climate change is both occurring _and_ caused by humans.

Ain't it fun when you can use the same fallacy and essentially the same argument and "prove" diametrically opposite conclusions?

For contrast, the following is _not_ Appeal To Consequences:

Human industry is producing massive amounts of CO<sub>2</sub>.  
CO<sub>2</sub> causes climate change regardless of source.  
Even minor alterations to the Earth's climate would be catastrophic for humanity.  
Q.E.D.: If humans wish to destroy themselves, humans should maintain or increase their current carbon emissions.

Instead, this is a contingent statement based on absolute facts that forms a chain of cause and effect.

    Appeal to Fear 

Also called:

-   _Argumentum ad metum_
-   _Argumentum in terrorem_
-   Scare 'Em Straight
-   Can't Get Away with Nuthin'

The slightly more subtle form of Appeal to Force, Appeal to Fear isn't a direct threat, but nevertheless is based on the idea that something terrible will happen unless you agree with a given position. The difference can be summarized like this:

**Appeal to Force:** "Agree that 2 + 2 = 5, or else I'll beat you up."

**Appeal to Fear:** "Agree that 2 + 2 = 5, or else social order will collapse, criminals will go free, and they will beat everyone including you up."

This is a fallacy because whether an outcome is frightening has no relevance to whether the initial statement is true or not. Social order may collapse if you disagree that 2 + 2 = 5 (as in _Nineteen Eighty-Four_), but that does not mean that 2 + 2 = 5. A type of Appeal to Consequences, where someone is supposed to be afraid of an outcome and therefore assume it to be true or false as a result.

In marketing, this fallacy is known as FUD ("Fear, Uncertainty, and Doubt") and is applied to the use of vague criticisms of opposing products in order to try to persuade consumers to buy their brand. Example: "Using non-Original Equipment Manufacturer replacement parts in your car could cause harm or permanent, unreliable damage to your engine. Avoid the risk and only buy Original Equipment Manufacturer parts."

    Appeal to Ignorance 

### Also called

-   Argument from Ignorance
-   Argument from Lack of Imagination
-   Argument from Personal Incredulity

The claim that a statement is true simply because it has not been proven false, or that a statement is false simply because it has not been proven to be true. More exactly, that if a claim A is incorrect, a separate claim B is automatically correct: it is thus a type of false dilemma, and based on Shifting the Burden of Proof onto whichever side of the argument you want to lose.

"It's clear from the knife in this man's back that he was murdered."

"You don't know for sure that's how the knife got in his back, therefore he was not murdered."

Or:

"Since you haven't found a murder weapon yet, it's obvious this man was poisoned."

The essence of the fallacy is that if the original argument cannot explain everything _right now_, it must be false: the person committing the fallacy discards the possibility of gathering more evidence. This makes it essentially a claim of personal omniscience; if the arguer cannot imagine a way for something to have happened, it is clearly impossible: it is thus closely related to the Perfect Solution Fallacy, where solution A is discarded due to failing to measure up to an idealized perfect solution B. In addition, it eliminates all _other_ possible explanations in favor of a preferred one: in the second example, for instance, the idea the victim was, say, strangled is simply discarded in favor of the preferred conclusion, without any clear reason.

Famously refuted by Carl Sagan with the statement, "Absence of evidence is not evidence of absence."

    Appeal to Pity 

Also called _Argumentum ad Misericordiam_, the Appeal to Pity is attempting to make someone feel sorry for either the arguer or the subject of the argument in order to convince them to accept the argument, regardless of its validity.

"Sir, you shouldn't fire me, even though I'm chronically late, bicker with all the other staff, and consistently fail to finish my tasks on time, because I have a sick wife and four children, and if I lose my job we'll be thrown out of our house and have to live on the street."

    Appeal to Ridicule 

Also known as the Appeal to Mockery, the Horse Laugh, or _reductio ad ridiculum_, the Appeal to Ridicule is a simplistic fallacy in which it is suggested an argument is false by presenting it in a way in which it appears silly and/or trivial. This is often also a strawman or an Appeal to Ignorance.

"According to quantum theory, an electron can be in two places at once! Have you ever heard anything so stupid? It must be wrong!"

This fallacy differs from _reductio ad absurdum_, a legitimate debating technique; there, it is demonstrated that an absurd conclusion naturally follows from the underlying logic of an opponent's argument, therefore showing the argument as invalid. However, an attempt at _reductio ad absurdum_ that itself uses faulty reasoning can leave you with this.

Also, just because an argument uses ridicule does not mean it runs afoul of this. A person who delivers a withering, logically sound counterattack in a mocking, rude manner is being a jerk. If the argument is still sound, it stands regardless of how insulting the phrasing is. It only becomes a fallacy when the arguer fails to explain _why_ what they are arguing against is stupid or ridiculous and just expects you to go with it.

A variation is _argumentum ad lapidem_ ("appeal to the stone"), in which a statement is dismissed as absurd, but with no proof that it's absurd.

    Appeal to Wealth 

Claiming that a position is correct because the rich or famous support it. This is the basis behind Celebrity Endorsements, especially when the celebrity's claim to fame is not relevant to the issue. See Screw the Rules, I Have Money! and Colbert Bump. Example: "I have read both of \[famous action movie star's\] interviews on the dangers of cooked foods, and so I think we should shift to all raw food."

    Argumentum ad Nauseam 

Also known as proof by assertion or the Big Lie Effect, _argumentum ad nauseam_ is repeating a statement until nobody cares to respond anymore, then claiming you're right since nobody contradicts you. A favourite variation is to insist you've refuted your opponent's argument previously without ever actually doing so, and then go on to state that you can't help that they didn't understand it. While it sounds simplistic, this fallacy can be maddeningly effective. In forums with content rules, the debater is often trying to frustrate their opponent into flaming them, hoping to win by default. The Nazis used the big lie to promote their antisemitic views. By repeating antisemitic tropes and false claims about Jews over and over, it increased acceptance of these views.

See also Argument of Contradictions, in which _both_ sides repeat their side of the argument briefly, rapidly, and back-and-forth, or simply shout something in the form of "Is not!" "Is too!" in the hope of wearing down an opponent or simply not being willing to back down or provide actual logical reasons.

    Bandwagon Fallacy 

The Bandwagon Fallacy is the suggestion that because something is becoming popular, it should be accepted quickly or the person being spoken to will lose out in the long run. The name comes from the classic idea of getting on the bandwagon before it leaves; in this fallacy, the fact that there are a lot of people on the bandwagon and it might leave are the _only_ reasons given to accept, with no reason why getting on the bandwagon is actually a good idea (or, for that matter, why there _is_ a bandwagon).

Some people using the bandwagon argument might give evidence on the number of people joining "their" side "xx% believe my point"). However, even if a majority of people were to believe that aliens have established an invasion staging base on the Moon, this doesn't prove that it's true.

This is referred to as _Fear of Loss_ in sales; a salesman will claim that he's only allowed to sign up a certain number of people to a fantastic deal and has already got most of his quota for today, so if the person he's speaking to doesn't act they stand to lose out.

There are also times this argument is valid, such as when there are what economists call network effects. In brief, if the value of a good or service changes based on the number of users, then pointing out the number of people using it could be valid. For example, when telephones were adopted, their value increased with every new telephone added to the network. If business software is used by many companies, being ubiquitous is a selling point. If no one else uses an instant messenger, it's useless, but if everyone uses it, it's more valuable to the end user. If all of one's friends use a specific social networking site and you want to use social media, it makes sense to follow your friends. If a cell phone company allows unlimited calls between two members of their networks, the number of clients they have and their demographics are both legitimate concerns. If most counties and companies are using a particular shipping container, rail-road gauge, or standard of measure, there's good reasons to adopt the same standards.

However, what makes these situations different from the Bandwagon Fallacy is that in these cases, it's clear why there's a bandwagon, and why getting on it is a good idea. With the Bandwagon Fallacy, however, no such reason is made clear.

    Begging the Question 

### Also called:

-   Petitio principii (Latin: "pursuit/attack of the source")

Also called "Circular Reasoning," begging the question is "proving" that something is true by taking your conclusion as one of your premises, usually done implicitly rather than explicitly. Few people are fooled by having your conclusion as your only premise, as in "Joe is mad at Jill, therefore Joe is mad at Jill." In rhetoric, such arguments are called _tautologies_, and they're essentially a pretty but meaningless way of saying the same thing twice. Therefore an argument which is begging the question often isn't obvious, even to the one making it. A premise may be substantially identical to or assume the truth of its conclusion, but be concealed by using different vocabulary, phrasing, sentence structure, or go unstated entirely.

Logic, meanwhile, has its own form of tautology: a statement or chain of statements which are sound, valid, and true under any condition.<sup>note&nbsp;</sup>  Begging the question is what happens when you confuse the two.

Put broadly, this fallacy applies to any argument where one or more premises are at least as contentious as the conclusion itself, and for the same reasons, such as:

Alice says she is honest.  
If an honest person says something, it must be true.  
Therefore Alice is an honest person, because an honest person says so.

An example where the fallacy is more hidden might go something like this:

The relationship between capitalists and laborers can only be exploitative, and mutually beneficial coexistence between them is impossible. Therefore, the path of historical development inevitably leads to socialist revolution.

In this example, both the premise and conclusion are based on Marxist ideology. If one were to accept one, by definition one already accepts the other. In other words it is not an "argument" at all, but merely a statement that says, "I am a Marxist."

Note that begging the question in arguments can be perfectly valid, logically speaking. However, they are not considered convincing because they do not prove anything other than what was already assumed.

"Begging the question" is often used colloquially to mean "raising the question". (Example: "With the rise of online media, this begs the question: do public libraries have a future?") This usage is a common Berserk Button for academics aware of the original meaning. It doesn't help that the original phrase was first translated from Greek into Latin, and from Latin into English, resulting in the confusing phrase, "Begging the question," which is incomprehensible to English speakers (there being no begging nor question involved) unless one is already aware of its meaning.

    Bulverism 

Bulverism happens when one party simply assumes that the other party is wrong and explains their reasons for wanting to believe it rather than addressing the argument itself. It combines Begging the Question with the Genetic Fallacy.

The Other Wiki expresses Bulverism as:

-   You claim that A is true.
-   Because of B, you personally desire that A should be true.
-   Therefore, A is false.

In short, it can be summarized as "You're only claiming X to be the case because you _want_ X to be the case!". This is fallacious since whether or not someone wants something to be true because it would benefit them personally has no bearing on whether or not it actually _is_.

The term was coined by C. S. Lewis in an essay of the same name in which he describes the (fictional) origin of the fallacy: a boy named Ezekiel Bulver heard his parents arguing when his mother said, "Oh, you say that because you are a man." at which point Bulver realized that "refutation is no necessary part of argument".

Lewis himself summed up the fallacy as "to assume without discussion that \[your opponent\] is wrong and then distract his attention from this (the only real issue) by busily explaining how he became so silly."

    Cab Driver's Fallacy 

Similar to the Sunk Cost Fallacy, this is having a particular goal in mind and refusing to give up on it, however impossible it seems, while also ignoring the possibility of doing even better. Named for the tendency of taxi drivers to try to earn a specific amount each day. On slow days they will keep going to reach the target, while on good days they will quit early as soon as the target is reached. They would do much better if they would go home early on slow days (thus saving gas, as well as wear and tear on the car, not to mention the driver) and keep going past their target if it's busy (when they barely have to drop off one fare before getting another one).

So far as cab drivers are concerned, this may be explained by risk-aversion. When it comes to something like income, most people are risk-averse - they would rather be guaranteed a steady flow of money rather than risk a large variance in the amount received (possibly negative) turn-by-turn, even if the latter would yield more money in the long run.

    Denying the Antecedent 

The flip side of Affirming the Consequent, this is where you say that because the initial conditions did not happen, the result is impossible.

If a person is wearing a hat, they have a head.  
I am not wearing a hat.  
Therefore I do not have a head.

Note that, by the contrapositive rule, these two fallacies are equivalent. For example, you could replace "If a person is wearing a hat, they have a head" by the logically identical statement "If a person has no head, they aren't wearing a hat" to turn the first example of denying the antecedent into an example of affirming the consequent.

    Fallacy Fallacy 

Also known as the Appeal to Fallacy, the Mister Spock Fallacy, the idea that "Fallacy means Wrong", the Zeroth Law of Fallacies, and the Bad Reasoning Fallacy, this concerns a claim that a position must be false because the argument used to get to that position is invalid or used a fallacy. It may sound like a rational thing to do since by definition a fallacious argument does not make sense, and this rule may seem like a mindscrewy special case, but...

Tom: All cats are animals. Ginger is an animal. This means Ginger is a cat.

Bill: You just committed the "affirming the consequent" logical fallacy. Sorry, you are wrong, which means that Ginger is not a cat.

Bill's rebuttal is an appeal to fallacy, because Ginger may very well be a cat; we just can't _assume_ so from Tom's argument.

In other words, pointing out somebody's fallacy is not fallacious in itself (you're doing it right), but using this as "proof" that their claim is false is the Fallacy Fallacy. Somebody arguing their point badly doesn't automatically mean they are wrong. The best you can say is that they have not convincingly supported it. This also applies to the Fallacy Fallacy itself: Bill's argument is a fallacy, but it would be the same fallacy to conclude that Ginger _is_ a cat because of that, since Tom's only "proof" is not a valid argument.

It should be noted that the burden of proof applies here: if the only _reason_ to accept a claim is a fallacious argument, accepting the claim anyway is _unreasonable_. If our null hypothesis is that Ginger is not a cat, Tom has given us no reason to change this assumption. As above, it may well be that Ginger actually _is_ a cat, but logic doesn't decide what's true, it decides what makes sense.

Another excellent example of how a false argument is combined with a true conclusion: in medicine, pressure around the brain can cause severe headaches. Ancient surgeons assumed that it must be demons in the patient's head causing the pain, and that exposing them to light would kill them or drive them out; therefore, they drilled holes in the patient's skull. The end result relieved the pressure and actually _did_ cure the headaches, even though their reasoning was entirely faulty.

An argument using fallacious reasoning is consequentially capable of being true. In logic, "invalid" (fallacious argument) and "false" are _not synonymous_ (See Sound/Valid/True for a more complete explanation of this. There are reasons why extensive Critical Thinking courses exist.) This is related to how logical argument is used as a tool rather than as a fact-in-itself, and that logical validity can sometimes be surpassed by an objective scientific fact.

It should be noted that there are some exceptions: namely, fallacies of distraction or relevance. A Strawman argument may still have a true conclusion, for example, but by definition it is an irrelevant conclusion since it does not address the opponent's real argument. Demonstrating the opposing argument is a strawman is therefore a valid rebuttal.

    Fallacy of Composition 

Claiming that because a statement is true of the parts, it must be true of the whole. For example:

Everything is made of atoms.

Atoms are invisible to the naked eye.

Therefore everything is invisible to the naked eye.

A type of generalisation fallacy.

    Fallacy of Division 

The opposite of the Fallacy of Composition, this happens when someone generalizes from a whole to the parts. For example:

A colony of ants can destroy a tree.  
Therefore, this ant can destroy that tree.

    Frozen Abstraction 

When an argument implicitly assumes that a specific member (or subset of specific members) of a wider class _is_ the wider class. Similar to the Fallacy of Composition in transferring one thing's properties to everything else in its class, and overlaps at times with False Dichotomy (which occurs when two members of a wider class are claimed to be the only members of the wider class and that a choice must be made between them). This fallacy is often caused by an unstated premise.

"An Egoist theory of ethics is a contradiction in terms".

This assumes that "ethics" is a synonym for "non-self-interested."

"Anarchism is not a political ideology because politics is about the role of the State; advocacy of a stateless society is not a political position."

This assumes that the role of the State must be an active one — i.e., the State must exist. (This applies whether one is arguing that Anarchism is not a valid political position, or that Anarchism is somehow "above" politics.)

    Genetic Fallacy 

Rejecting (or accepting) something solely on the basis of its origin, without looking at meaning or context. This ignores the fact that even a less credible source is sometimes, or can be, right. Alternately, that a more credible source is sometimes, or can be, wrong.

This is seen in any case where a source is either highly disparaged or esteemed. Sources will commonly be accepted or dismissed out of hand without looking into the actual validity of their facts or arguments.

    Human Nature Fallacy 

There are many people in the world who would be considered bad and would be seen as the "worst humanity has to offer". However, there are also just as many people who actively try to help whoever they can and to try to make the world a better place, even if they see the worst aspects of such.

However, people who assume that such actions were the result of human nature that is present in all human beings, tend to forget about those other kinds of people who actively try to help people in need (or at least support those, but cannot do much about it). These characters would assume that such actions are reflective of the entire human race, making flimsy claims of many people who do help only do so out of Pride and publicity (while there are some who do that, there are also much more people who genuinely want to help) and that ideas of hatred, prejudice and self-destruction are inherent in _all human beings._ They all reject claims of Rousseau Was Right and the idea of a Blank Slate, replacing them with Humans Are Bastards (or the real monsters in certain cases). Sometimes, they would deny that they share those aspects with humanity, claiming that their suffering was of the actions of humanity (when it could be their own fault) or embrace that they're part of humanity and use that as an excuse for their actions.

More blatant examples include dismissing the victims of such atrocities as being just as bad as the perpetrators, including children as part of their perceived Human Nature and igniting a Family Feud between family members, just because they perceive them as bastards deep down, no matter how they treated them.

The other way around is the assumption of all of humanity being good deep down, no matter how cruel their actions may be. Some may say that such actions were only brought upon due to their upbringing. Whilst a person can be influenced by their upbringing, characters who believe humanity is inherently good from birth would not accept that there are people who are deep down cruel. They would try to reason with even the most negative aspects of humanity, preferring to appeal to whatever little or no aspect of goodwill they have over actively combating them. They would also not recognize that there are people who are completely beyond redemption.

The more lighthearted variant is when someone assumes that all humans share a similar opinion on something, or similar habits and the like, when it's most likely not true. Such as "everyone likes spicy foods" or "everyone likes a certain film" or "everyone thinks about sex".

This idea is rarely treated as a necessary worldwide view in fiction, but when it does happen, there is a high chance of Too Bleak, Stopped Caring or Sweetness Aversion and accusations of the Author expressing this view.

See also Tragic Bigot and Appeal to Inherent Nature. Compare Blank Slate, Humans Are Flawed. Contrast Humans Are Bastards, In Your Nature to Destroy Yourselves, Hobbes Was Right (for the cynical version) and Humans Are Good, Rousseau Was Right (for the idealistic version). Also contrast Humans Are Indexed, which list common human archetypes.

    Hypostatization 

Sometimes related to the Four Terms Fallacy, this is treating an abstract idea as a physical object. For example, "Eating ice cream feels good. Therefore, we should give ice cream to criminals, so they become good." This assumes that "good" is a thing that can be measured and which is a physical property of ice cream — in fact "good" is an unmeasurable and quite subjective concept. Similarly, you can't go down to the store and pick up a can of consideration or a box of blue; they are _attributes_ of things, but do not exist independently of them.

A variation is treating a thought experiment as a physically workable one; for example, imagining that one could use Schrödinger's box apparatus to actually cause quantum superposition of a cat.

    Irrelevant Thesis 

Also called _ignoratio elenchi_ ("ignoring refutation") or an irrelevant conclusion, this happens when you have not refuted the opposing position at all, but are acting as though you did. It's really a superfallacy, in the same way that "Rule of Cool" is a supertrope; there are a number of fallacies which are all types of "Ignoratio Elenchi", among them all Appeals To Consequences, all Appeals To Emotion, all Strawmen and Red Herrings, Ad Baculum, Ad Nauseum, and all Ad Hominems.

    Loaded Words 

Loaded words or loaded language describes the misleading use of emotionally loaded language in order to win an argument.

Besides a word's definition, most words have a connotation that implies that its subject is either good or bad. For example, both the words "cabin" and "shack" mean basically the same thing, but one word has a positive (or at least neutral) connotation and the other has a negative connotation. Using a loaded term by itself isn't fallacious, but using loaded terms as a basis for an argument is. Using a loaded term to imply that the subject in question is bad when the point of your argument is that it's bad is also another form of Begging the Question. Not to be confused with Loaded Trope Word, which is when a word has a double meaning on this website.

    Motte and Bailey 

Switching a hard to defend position for a more easily defended (but superficially similar) one when the former position is challenged.

It's useful to visualize the type of medieval castle for which the fallacy is named. The bailey (weak argument) is a lightly fortified field containing useful and valuable things like smithies and stables. The motte is a heavily fortified tower on a hill. The lord and his men would defend the bailey if they could, but would retreat into the motte if things got hairy. And when the attackers left, they would go back down into the bailey and restore that. In the same way, a person can switch between arguments. It's something of a reverse form of the strawman fallacy, where rather than misrepresenting their opponent with a weak argument, the arguer (temporarily) replaces their own argument with a stronger one.

For example: let's say a faculty member at a school says that building a new expensive science building would improve student performance. Another faculty member counters that most of the money would be better spent hiring better science teachers and starting new student support programs. The former faculty member says "look, all I'm saying is we need to update those old classrooms." The problem is that they weren't originally saying that, they had a specific proposal, and, when that proposal was attacked, made it seem like they were just raising awareness for the issue.

    Non Sequitur Fallacy 

_Non Sequitur_ is a Latin term literally meaning "it does not follow," and is commonly seen in discussions of logic; it's a whole _class_ of fallacies including Affirmation of the Consequent, Denial of the Antecedent, Undistributed Middle and several others. Broadly, it applies to any argument where the conclusion does not flow naturally from the premises. Non Sequiturs are an important element in humour, but they're still fallacies when used as part of a logical argument.

Often, a non sequitur results from the writer believing that the statement results from an "obvious" argument that doesn't need to be explicitly stated.

For when this _actually works as an argument_, see Chewbacca Defense. When this is to such an extreme that attempts to consider it in any rational manner results in maddening frustration, it is Insane Troll Logic.

    Process of Elimination Fallacy 

Also called:

-   _Arcane Explanation_
-   _Holmesian Fallacy_
-   _Sherlock Holmes Fallacy_

This fallacy happens when an explanation is considered "correct" after other alternative explanations have been ruled out. It is named for the quote by Sherlock Holmes from various stories where he says that when one eliminates all which is impossible, whatever is left is the truth no matter how improbable.

For this maxim to work, that means one has to find all possible explanations and eliminate them one by one. This however requires omniscience, can lead to very improbable explanations and the real answer may be one that was never considered. If the science behind the right or wrong explanation wasn't known at the time (such as being considered magic or of the gods), see Science Marches On.

    Proof by Examples 

Also called an inappropriate or hasty generalization or the No Limits Fallacy, this fallacy happens when someone takes one or more non-exhaustive examples from a group that have a property, and making a generalization that everything in that group has that property.

3 is odd, and it is a prime number.  
13 is odd, and it is a prime number.  
97 is odd, and it is a prime number.  
Therefore, all odd numbers are prime numbers.

Or in other words, this fallacy is about mistaking inductive reasoning for deductive reasoning. A common version is to assume that anything can be extended off to infinity, or that since having a little of something is good, having more must be better. It's a line of thinking commonly used by those talking about future technology.

"If I told you fifty years ago that you'd have a phone smaller than a deck of cards, that computers would be small enough to put into a pocket, and that your car would be able to call for help if it was involved in a crash, you'd have laughed at me. So if you say that faster-than-light travel is impossible, you're just being small-minded, since technology continues to improve all the time."

    Prosecutor's Fallacy 

Rejecting an explanation for a particular event on the grounds that it requires a rare or unlikely event to have occurred, while ignoring that the favoured explanation might actually be even less likely. This fallacy ignores the fact that 'improbable' doesn't mean 'impossible'. Like the Gambler's Fallacy, this is also a statistical error.

As the name implies, this fallacy is a favorite of prosecutors in legal cases and sometimes in procedural shows like CSI — it can be quite tempting to argue, "How likely is it that this really happened the way the defendant said it did, if the odds of it happening that way are 1 in 10 million? Which is more believable — that he's lying or that something that improbable really happened?" It also lends itself well to Cassandra Truth plots.

An argument of this form often ignores that unusual cases are, well, unusual. We tend to notice unusual events more than common events, and the very fact that the issue is being argued over guarantees that it is likely an unusual event. For instance, if a practised hunter accidentally shoots his friend, one could argue that the odds of him making such a serious error is very small. But then, the alternative explanation is that the hunter _purposefully_ shot his friend, which is also somewhat unlikely. In the end, the event itself can _only_ be explained by one of several improbable explanations, and so the fact that they _are_ improbable ceases to be relevant.

    Retrospective Determinism 

Assuming that because something happened it was inevitable; often, the follow-on is a hasty generalisation that it will inevitably happen _again_ in the same situation, leading to tropes like Hitler's Time Travel Exemption Act and Planet of Hats.

Alice: Hey Bob, how's the knee?  
Bob: After I went out for a walk, I was bound to trip and break my knee.

Bob gives no real reason as to why this was the only possible result, or even why it was the most likely; it differs from False Cause in that he _did_ break his knee as a result of going out for a walk. He might follow on by cautioning Alice to avoid going outside, lest she suffer the same fate. Often happens during arguments over Alternate History, as someone attempts to argue for the historical result being inevitable.

More seriously, people use this to comfort themselves after losing someone, saying "it was their time." Unless they really believe that each person's time of death is determined beforehand, they don't really mean it (especially as that would be very depressing).

    Reverse Slippery Slope Fallacy 

Arguing that because a slippery slope has failed to appear, further travel down the slope is safe. Note that such arguments can actually legitimize a Slippery Slope Fallacy; the speaker has established a precedent of using previous travel down the slope to justify further travel down the slope; thus, one is justified in worrying that this new action will in turn be used to justify even more actions.

    Semantic Slippery Slope Fallacy 

The Semantic Slippery Slope is a fallacy that occurs when someone argues that because there is no clear line between two concepts or because they "only" differ in degree, they are either the same thing or neither exists at all.

This fallacy is somewhat of an inversion of the False Dichotomy, in which someone ignores any grey area and posits that only two contrasts exist. The Semantic Slippery Slope emphasizes any grey area and disregards clear differences. In short, saying the concept is too vague for any real decision to be made. The Semantic Slippery Slope Fallacy is also related to the regular Slippery Slope Fallacy insofar as committing the former will often cause the latter by inferring that one thing will inevitably cause the second thing, or that they're the same thing altogether.

    Shifting the Burden of Proof 

Generally in a debate, the negative assumption is taken as the default; in other words, if there is not adequate proof given that something _does_ happen, it will be taken that it does not. The Burden of Proof Fallacy occurs when an attempt is made to shift this burden to the wrong side. For example:

_"You can't prove that your house is **not** full of invisible landmines, so you'd better stay still in case you accidentally set one off."_

This is a good demonstration of why the negative side doesn't bear the burden of proof; it is for all intents impossible to demonstrate something is absolutely incapable of happening, and it would be impossible to live one's life in light of all the things that might be true. It's far easier to demonstrate proof of the positive (if it exists). Put more simply, if someone has advanced no good reason to believe something is true, believing it is true anyway is unreasonable. This does not necessarily mean it is untrue (see the Fallacy Fallacy), but it does mean it is not logical to believe it is true.

Linguistic trickery can often be used to make a negative appear to be a positive (for example, claim that rejecting the existence of the invisible landmines is a positive claim that "I can explain everything in the universe right now"). It pays to be careful in evaluating which side the burden actually belongs on.

One popular form of shifting the burden of proof is to demand your opponent ‘do their own research’. This places the onus for proving the point you're trying to make onto them. This particularly applies if the research they're supposed to perform is defined extremely vaguely, such as ‘take some classes’, ‘you can find dozens of examples’ or even ‘use common sense’.

    Special Pleading 

This is the fallacy of asking to be given an exemption to a rule that others are held to. It's typically used as an excuse for special treatment others don't receive, or to win arguments by claiming to have special insights others don't have.

"I'm a judge, so I shouldn't have to stop at red lights."

This is fallacious because even if someone has certain expertise or is part of a specific group, they still have to provide evidence and cogent reasons for their position.

Another example could be formulated like this:

Everyone has a duty to help the police do their job, no matter who the suspect is. That is why we must support investigations into corruption in the police department. No person is above the law. Of course, if the police come knocking on my door to ask about my neighbors and the robberies in our building, I know nothing. I’m not about to rat on anybody.

In this example, the principle of helping the police is applied to investigations of police officers but not to one’s neighbors.

    Spotlight Fallacy 

Also known as misleading vividness or the Volvo Fallacy, this is a close cousin to the Anecdotal Fallacy. The Spotlight Fallacy is making a generalization based on how much news coverage a subject gets. This is fallacious because the news media tends to focus heavily on events that are less common in real life. However, because the news covers them so extensively, it's an easy mistake to make.

It's said that "'Dog Bites Man' is not news; 'Man Bites Dog' is news." Using that example, this fallacy is when somebody assumes that men biting dogs is more common than the reverse, because it appears in the papers more often.

Compare The New Rock & Roll and Cowboy BeBop at His Computer.

    Stolen Concept 

A fallacy in which one or more of the concepts (or premises) on which an argument depends are (usually implicitly) denied by the argument itself, thus meaning the arguer is taking two or more opposed positions at the same time. Named by Ayn Rand (and discussed in more detail here). Popular in anti-science literature where scientific processes will be used in an attempt to discredit their own underlying assumptions.

"The latest research in zero-point field quantum physics shows that it is possible to make a perpetual motion machine, and that the first law of thermodynamics does not apply in the quantum domain."

Zero-point field theories include conservation of mass / energy as an assumption. They would disprove themselves if they actually made this conclusion.

"Quantum physics has proven that reality does not exist objectively." (the less advanced version of the above argument).

The notion of "proof" assumes the objective existence of something to prove in the first place. Additionally, if nothing existed objectively, there would be no reliable methods of proof, including quantum physics.

This is similar to the valid _reductio ad absurdum_ argument, which attempts to disprove a statement by assuming it to be true and showing how that leads to a contradiction. "Quantum physics has proven that reality does not exist objectively" would be a strong argument that (some aspect of) quantum physics is _bad science_, but even if it were true it could never prove that reality is not objective.

    Strawman Fallacy 

The Strawman Fallacy occurs when a debater constructs a more easily defeated version of their opponent's position to attack, rather than addressing their real arguments. The fallacy takes its name from straw dummies used in old-fashioned combat training; these dummies were made to look like a potential opponent, but provide no actual resistance. The fallacy itself is comparable to defeating such a dummy, then proclaiming you have defeated an actual opponent.

_"The NRA supports the right to bear arms, so they support private ownership of nuclear weapons."_

While most people will not be fooled by a blatant misrepresentation of their position, careful use of a strawman can make them defend a carefully undermined version of their position, allowing their opponent to apparently destroy them with a prepared rebuttal. However, it's more often used to get the _audience_ on one's side than it is to confuse the opponent, especially when it's coupled with an Ad Hominem implying that the opponent is immoral for "holding" the strawmanned position.

The opposite is called the Steelman, where one argues against the _best_ possible version of an opponent's position. It has a brother called the "weakman fallacy" or "nutpicking" where an opponent who holds the worst possible version of an argument (or is just bad at debating) is selected to represent an entire world view.

    Toupee Fallacy 

The Toupee Fallacy is when a debater claims that all examples of a subject conform to a specific quality because they've never seen one that hadn't, ignoring that any examples they _did_ see that didn't have that quality they didn't recognize as examples.

Consider this statement: "Every toupee is a Dodgy Toupee. I know because I've never seen one that looked real." Naturally, if the speaker _did_ see a toupee that looked real, they would simply assume it was actual hair - that is, after all, what a toupee is _meant to do_.

The Toupee Fallacy comes up most often in the discussion of transgender individuals; a person will claim (to use one example) they've never seen a transgender woman that didn't obviously look like a man in a dress. Of course, they've likely seen dozens, but simply assumed they were biologically female.

    Two Negative Premises 

If A is not B, and B is not C, then A is C. This is always invalid logic (although it may happen to be true), as it is not possible to make a valid conclusion from two negative premises; logic is not arithmetic. This is a fallacy because simply identifying what something _isn't_ doesn't identify what it _is_.

No Jews are Muslims.  
No Muslims are Christians.  
Therefore Jews are Christians.

No dogs are reptiles.  
No reptiles are magenta.  
Dogs are magenta.

No dogs are reptiles.  
No reptiles shoot lasers out of their eyes.  
Dogs shoot lasers out of their eyes.

    Undistributed Middle 

This fallacy occurs when the middle term of a standard three-step syllogism is not distributed<sup>note&nbsp;</sup>  in either premise. This picture<small>◊</small> is a case of undistributed middle. Using that image, "black and white" is the middle term, the term that appears in both premises; it is undistributed because neither premise refers to _all_ things that are "black and white". Newspapers are black and white as well, and they are neither penguins nor old TV shows. "Things that are black and white" is the superset, and it contains many subsets that do not overlap at all. In casual use, undistributed middle can be hard to spot.

Liberals always want to raise taxes.  
Alice says that she's a conservative, but she also says that the sales tax needs to be raised.  
She's lying about being a conservative; she's really a liberal.

The point is not how "liberal" and "conservative" are defined; it's that at no point is it established that only liberals want to raise taxes. Put another way, saying "All liberals are people who want to raise taxes" is not the same as saying "All people who want to raise taxes are liberals."

    Zero-Sum Fallacy 

In game theory terms, a zero-sum game has one person's gain mean another's loss. This fallacy applies the principle to a situation where it isn't true, or at least isn't the only possible outcome. While many things in life really do come at a cost, not everything exists in a fixed quantity, and some people apply this to concepts such as love, happiness, and goodness.

Alice and Bob love their daughter Claire.  
If they have another child, they'll only love Claire half as much, because the other half of that love will go towards their new kid.

Often used as one of the Jerk Justifications, with said jerk claiming that to benefit another would be to harm themselves and that their wellbeing depends on other's suffering, ignoring the possibility of mutually beneficial acts and situations. A favourite of The Social Darwinist, who believes the strong must flourish at the expense of the weak. In economics, the idea that there's a finite number of jobs to go round is also known as the fixed pie fallacy or the lump of labour fallacy.

___

### **Alternative Title(s):** Logical Fallacy, Affirming The Consequent, Denying The Antecedent, Reification, Lokis Wager, Semantic Slippery Slope, Straw Man Argument, The Cab Drivers Fallacy, Continuum Fallacy, Just World Fallacy, Inappropriate Generalization, Hasty Generalization, No Limits Fallacy, Anecdotal Fallacy, Appeal To Consequences, Appeal To Fear, Appeal To Ignorance, Appeal To Pity, Appeal To Ridicule, Appeal To Wealth